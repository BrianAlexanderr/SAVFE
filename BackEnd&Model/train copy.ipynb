{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "class FaceRecognitionModel:\n",
    "    def __init__(self, \n",
    "                 dataset_path, \n",
    "                 img_height=299, \n",
    "                 img_width=299, \n",
    "                 batch_size=32, \n",
    "                 num_classes=None,\n",
    "                 dropout_rate=0.5,\n",
    "                 l2_regularization=1e-3):\n",
    "        \"\"\"\n",
    "        Initialize Face Recognition Model with Inception V3\n",
    "        \n",
    "        Parameters:\n",
    "        - dataset_path: Path to the directory containing face images\n",
    "        - img_height: Image height for resizing (default Inception V3 input)\n",
    "        - img_width: Image width for resizing\n",
    "        - batch_size: Training batch size\n",
    "        - num_classes: Number of face classes/identities\n",
    "        \"\"\"\n",
    "        self.dataset_path = dataset_path\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.batch_size = batch_size\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.l2_regularization = l2_regularization\n",
    "        \n",
    "        # Detect number of classes automatically\n",
    "        if num_classes is None:\n",
    "            self.num_classes = len(os.listdir(dataset_path))\n",
    "        else:\n",
    "            self.num_classes = num_classes\n",
    "        \n",
    "        # Model and training attributes\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.best_model = None\n",
    "        \n",
    "    def _create_data_generators(self):\n",
    "        \"\"\"\n",
    "        Create data generators with aggressive augmentation\n",
    "        \"\"\"\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input,\n",
    "            rotation_range=20,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            brightness_range=(0.8, 1.2),\n",
    "            fill_mode='nearest',\n",
    "            validation_split=0.2\n",
    "        )\n",
    "        \n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            self.dataset_path,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training'\n",
    "        )\n",
    "        \n",
    "        validation_generator = train_datagen.flow_from_directory(\n",
    "            self.dataset_path,\n",
    "            target_size=(self.img_height, self.img_width),\n",
    "            batch_size=self.batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation'\n",
    "        )\n",
    "        \n",
    "        return train_generator, validation_generator\n",
    "    \n",
    "    def build_model(self, learning_rate=1e-4):\n",
    "        \"\"\"\n",
    "        Build Inception V3 transfer learning model\n",
    "        \"\"\"\n",
    "        base_model = InceptionV3(\n",
    "            weights='imagenet', \n",
    "            include_top=False, \n",
    "            input_shape=(self.img_height, self.img_width, 3)\n",
    "        )\n",
    "        \n",
    "        # Freeze base model layers\n",
    "        for layer in base_model.layers[-50:]:\n",
    "            layer.trainable = False\n",
    "        \n",
    "        # Add custom classification layers\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        # x = Dense(\n",
    "        # 512, \n",
    "        # activation='relu', \n",
    "        # kernel_regularizer=l2(self.l2_regularization)\n",
    "        # )(x)\n",
    "        # x = BatchNormalization()(x)\n",
    "        # x = Dropout(self.dropout_rate)(x)\n",
    "        \n",
    "        x = Dense(\n",
    "            256, \n",
    "            activation='relu', \n",
    "            kernel_regularizer=l2(self.l2_regularization)\n",
    "        )(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Dropout(self.dropout_rate)(x)\n",
    "\n",
    "        predictions = Dense(\n",
    "            self.num_classes, \n",
    "            activation='softmax',\n",
    "        )(x)\n",
    "\n",
    "        \n",
    "        self.model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "        # self.model.summary()\n",
    "        \n",
    "        # Compile model\n",
    "        self.model.compile(\n",
    "            optimizer=Adam(learning_rate=learning_rate),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "\n",
    "        return self.model\n",
    "    \n",
    "    def train_with_k_fold(self, epochs=5, k_folds=5):\n",
    "        \"\"\"\n",
    "        Train model using K-Fold Cross Validation\n",
    "        \"\"\"\n",
    "        train_generator, validation_generator = self._create_data_generators()\n",
    "        \n",
    "        # K-Fold Cross Validation\n",
    "        kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "        \n",
    "        # Callbacks\n",
    "        early_stopping = EarlyStopping(\n",
    "            monitor='val_accuracy', \n",
    "            patience=10, \n",
    "            restore_best_weights=True\n",
    "        )\n",
    "        \n",
    "        checkpoint = ModelCheckpoint(\n",
    "            'best_face_recognition_model.keras',\n",
    "            monitor='val_accuracy', \n",
    "            save_best_only=True\n",
    "        )\n",
    "        \n",
    "        fold_histories = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(train_generator.classes), 1):\n",
    "            print(f\"Training Fold {fold}\")\n",
    "            \n",
    "            history = self.model.fit(\n",
    "                train_generator,\n",
    "                validation_data=validation_generator,\n",
    "                epochs=epochs,\n",
    "                callbacks=[early_stopping, checkpoint]\n",
    "            )\n",
    "            \n",
    "            fold_histories.append(history.history)\n",
    "        \n",
    "        # Load best model\n",
    "        self.best_model = tf.keras.models.load_model('best_face_recognition_model.keras')\n",
    "        \n",
    "        return fold_histories\n",
    "    \n",
    "    def evaluate_model(self, validation_generator):\n",
    "        \"\"\"\n",
    "        Evaluate model performance and generate reports\n",
    "        \"\"\"\n",
    "        # Predictions\n",
    "        predictions = self.best_model.predict(validation_generator)\n",
    "        predicted_classes = np.argmax(predictions, axis=1)\n",
    "        true_classes = validation_generator.classes\n",
    "        \n",
    "        # Classification Report\n",
    "        class_report = classification_report(\n",
    "            true_classes, \n",
    "            predicted_classes, \n",
    "            target_names=validation_generator.class_indices.keys()\n",
    "        )\n",
    "        print(\"Classification Report:\\n\", class_report)\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        cm = confusion_matrix(true_classes, predicted_classes)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.close()\n",
    "        \n",
    "    def plot_training_history(self, histories):\n",
    "        \"\"\"\n",
    "        Plot training accuracy and loss\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Accuracy Plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        for history in histories:\n",
    "            plt.plot(history['accuracy'], label='Training Accuracy')\n",
    "            plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
    "        plt.title('Model Accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Loss Plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        for history in histories:\n",
    "            plt.plot(history['loss'], label='Training Loss')\n",
    "            plt.plot(history['val_loss'], label='Validation Loss')\n",
    "        plt.title('Model Loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('training_history.png')\n",
    "        plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "def main():\n",
    "    # Configuration\n",
    "    dataset_path = \"Celebrity Faces Dataset/\"\n",
    "    \n",
    "    # Initialize and build model\n",
    "    face_recognition = FaceRecognitionModel(dataset_path)\n",
    "    model = face_recognition.build_model()\n",
    "    \n",
    "    # Train with K-Fold Cross Validation\n",
    "    histories = face_recognition.train_with_k_fold()\n",
    "    \n",
    "    # Plot training history\n",
    "    face_recognition.plot_training_history(histories)\n",
    "    \n",
    "    # Evaluate model\n",
    "    train_generator, validation_generator = face_recognition._create_data_generators()\n",
    "    face_recognition.evaluate_model(validation_generator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 886 images belonging to 10 classes.\n",
      "Found 221 images belonging to 10 classes.\n",
      "Training Fold 1\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 6s/step - accuracy: 0.1641 - loss: 3.5512 - val_accuracy: 0.3710 - val_loss: 2.3272\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 10s/step - accuracy: 0.4966 - loss: 1.9697 - val_accuracy: 0.6244 - val_loss: 1.8538\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 5s/step - accuracy: 0.6673 - loss: 1.5131 - val_accuracy: 0.7059 - val_loss: 1.4741\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 5s/step - accuracy: 0.7674 - loss: 1.1251 - val_accuracy: 0.7692 - val_loss: 1.1955\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 5s/step - accuracy: 0.8481 - loss: 0.8836 - val_accuracy: 0.8824 - val_loss: 0.8919\n",
      "Training Fold 2\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 5s/step - accuracy: 0.9044 - loss: 0.7778 - val_accuracy: 0.9276 - val_loss: 0.7621\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - accuracy: 0.9282 - loss: 0.6848 - val_accuracy: 0.9140 - val_loss: 0.7461\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - accuracy: 0.9299 - loss: 0.6692 - val_accuracy: 0.9050 - val_loss: 0.7239\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - accuracy: 0.9399 - loss: 0.6487 - val_accuracy: 0.9367 - val_loss: 0.6481\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.9594 - loss: 0.5745 - val_accuracy: 0.9276 - val_loss: 0.6548\n",
      "Training Fold 3\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 5s/step - accuracy: 0.9648 - loss: 0.5830 - val_accuracy: 0.9638 - val_loss: 0.5745\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.9793 - loss: 0.5373 - val_accuracy: 0.9457 - val_loss: 0.5911\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.9738 - loss: 0.5451 - val_accuracy: 0.9548 - val_loss: 0.5753\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - accuracy: 0.9705 - loss: 0.5428 - val_accuracy: 0.9593 - val_loss: 0.5756\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - accuracy: 0.9721 - loss: 0.5164 - val_accuracy: 0.9683 - val_loss: 0.5713\n",
      "Training Fold 4\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.9860 - loss: 0.5035 - val_accuracy: 0.9548 - val_loss: 0.5820\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 5s/step - accuracy: 0.9933 - loss: 0.4756 - val_accuracy: 0.9548 - val_loss: 0.5464\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - accuracy: 0.9854 - loss: 0.4848 - val_accuracy: 0.9819 - val_loss: 0.5184\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.9851 - loss: 0.4875 - val_accuracy: 0.9683 - val_loss: 0.5200\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - accuracy: 0.9931 - loss: 0.4708 - val_accuracy: 0.9864 - val_loss: 0.4860\n",
      "Training Fold 5\n",
      "Epoch 1/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.9892 - loss: 0.4736 - val_accuracy: 0.9819 - val_loss: 0.4733\n",
      "Epoch 2/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - accuracy: 0.9911 - loss: 0.4661 - val_accuracy: 0.9864 - val_loss: 0.4684\n",
      "Epoch 3/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - accuracy: 0.9965 - loss: 0.4583 - val_accuracy: 0.9910 - val_loss: 0.4709\n",
      "Epoch 4/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - accuracy: 0.9988 - loss: 0.4459 - val_accuracy: 0.9955 - val_loss: 0.4706\n",
      "Epoch 5/5\n",
      "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - accuracy: 0.9901 - loss: 0.4675 - val_accuracy: 0.9457 - val_loss: 0.6127\n",
      "Found 886 images belonging to 10 classes.\n",
      "Found 221 images belonging to 10 classes.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step\n",
      "Classification Report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      " Jennifer Lawrence       0.06      0.05      0.05        20\n",
      "       Johnny Depp       0.14      0.15      0.15        20\n",
      " Leonardo DiCaprio       0.05      0.05      0.05        20\n",
      "         Megan Fox       0.05      0.05      0.05        20\n",
      "    Michael Wijaya       0.05      0.05      0.05        21\n",
      "  Robert Downey Jr       0.21      0.20      0.21        20\n",
      "Scarlett Johansson       0.24      0.25      0.24        40\n",
      "        Tom Cruise       0.10      0.10      0.10        20\n",
      "         Tom Hanks       0.00      0.00      0.00        20\n",
      "        Will Smith       0.10      0.10      0.10        20\n",
      "\n",
      "          accuracy                           0.11       221\n",
      "         macro avg       0.10      0.10      0.10       221\n",
      "      weighted avg       0.11      0.11      0.11       221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
